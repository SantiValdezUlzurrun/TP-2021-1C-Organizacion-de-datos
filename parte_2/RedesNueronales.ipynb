{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0331223",
   "metadata": {},
   "source": [
    "## Trabajo Práctico 2: Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc85edff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ebcfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b855e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_STATE = 19 * 103785\n",
    "\n",
    "GSPREADHSEET_DOWNLOAD_URL = (\"https://docs.google.com/spreadsheets/d/{gid}/export?format=csv&id={gid}\".format)\n",
    "\n",
    "DF_TRAIN_GID = '1-DWTP8uwVS-dZY402-dm0F9ICw_6PNqDGLmH0u8Eqa0'\n",
    "DF_HOLDOUT_GID = \"1ObsojtXfzvwicsFieGINPx500oGbUoaVTERTc69pzxE\"\n",
    "\n",
    "def tiene_n_missings(x, n):\n",
    "    acum = 0\n",
    "    for i in range(len(x)):\n",
    "        if x[i]:\n",
    "            acum += 1\n",
    "    return n <= acum\n",
    "\n",
    "\n",
    "def feature_engineering(df):\n",
    "    lista_de_missings = [tiene_n_missings(x, 3) for x in df.isna().to_numpy()]\n",
    "    df_3_missings = df.reset_index()[lista_de_missings].set_index('index')\n",
    "    df.drop(df_3_missings.index, inplace = True)\n",
    "    df = df.replace({'trabajo': np.nan, 'categoria_de_trabajo': np.nan},'No contesto')\n",
    "    df = df.replace({'barrio': np.nan},'Palermo')\n",
    "    mapa = {'Palermo' : 'C14','Belgrano' : 'C13','San Isidro' : 'S.I','Villa Urquiza' : 'C12','Recoleta' : 'C2','La Boca' : 'C4','Agronomia' : 'C15','Almagro' : 'C5','Balvanera' : 'C3','Puerto Madero' : 'C1','Caballito' : 'C6','Boedo' : 'C5','Barracas' : 'C4','Chacarita' : 'C15','Coghland' : 'C12','Floresta' : 'C10','Constitucion' : 'C1','Colegiales' : 'C13','Flores' : 'C7','Liniers' : 'C9','Monte Castro' : 'C10','Mataderos' : 'C9','Nueva Pompeya' : 'C4','Monserrat' : 'C1','nuñez' : 'C13','Parque Chacabuco' : 'C7','Parque Avellaneda' : 'C9','Villa Luro' : 'C10','Parque Chas' : 'C15','La Paternal' : 'C15','Retiro' : 'C1','Villa Devoto' : 'C11','Villa Soldati' : 'C8','San Telmo' : 'C1','Villa Real' : 'C10','Santa Rita' : 'C11','Villa General Mitre' : 'C11','Versalles' : 'C10','Velez Sarsfield' : 'C10','Villa Pueyrredon' : 'C12','Cilla Riachuelo' : 'C8'}\n",
    "    df['comuna'] = df['barrio'].apply(lambda x: mapa.get(x))\n",
    "    df_gente_sin_trabajo_con_horas_registradas = df[(df['categoria_de_trabajo'] == 'sin_trabajo') & (df['horas_trabajo_registradas'] > 0)]\n",
    "    df.drop(df_gente_sin_trabajo_con_horas_registradas.index, inplace = True)\n",
    "    df['rol_familiar_registrado'] = df['rol_familiar_registrado'].apply(lambda x: 'casado' if x == 'casada' else x)\n",
    "    df['estado_marital'] = df['estado_marital'].apply(lambda x: 'matrimonio' if x == 'matrimonio_civil' or x == 'matrimonio_militar' else x)\n",
    "    df = df.drop(['educacion_alcanzada'],axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def obtenerDF(GID):\n",
    "    return pd.read_csv(GSPREADHSEET_DOWNLOAD_URL(gid=GID), skiprows=0)\n",
    "\n",
    "def obtenerDFTraining():\n",
    "    return obtenerDF(DF_TRAIN_GID)\n",
    "\n",
    "def obtenerDFHoldout():\n",
    "    return obtenerDF(DF_HOLDOUT_GID)\n",
    "\n",
    "def preprocesar_df_min_max_scaler(X : pd.DataFrame):\n",
    "    X = pd.get_dummies(X)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X)\n",
    "    return scaler.transform(X)\n",
    "\n",
    "def preprocesar_df_pca(df , dim):\n",
    "    Y = df['tiene_alto_valor_adquisitivo']\n",
    "    X = df.drop(columns=['tiene_alto_valor_adquisitivo'])\n",
    "    X = preprocesar_df_min_max_scaler(X)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=RANDOM_STATE)\n",
    "    \n",
    "    pca = PCA(dim)\n",
    "    x_train_pca = pd.DataFrame(pca.fit_transform(x_train))\n",
    "    x_test_pca = pca.transform(x_test)\n",
    "    \n",
    "    return (x_train_pca,x_test_pca,y_train,y_test)\n",
    "\n",
    "def preprocesar_data_frame(df : pd.DataFrame):\n",
    "    df = feature_engineering(df)\n",
    "    y = df['tiene_alto_valor_adquisitivo']\n",
    "    X = df.drop(columns=['tiene_alto_valor_adquisitivo'])\n",
    "    return (X, y)\n",
    "\n",
    "\n",
    "def prepros_dummies(data):\n",
    "    \n",
    "    data_prepos = pd.get_dummies(data[['ganancia_perdida_declarada_bolsa_argentina','trabajo',\n",
    "                                      'estado_marital','edad','genero',\"anios_estudiados\",\"horas_trabajo_registradas\"]])\n",
    "    \n",
    "    data_prepos['ganancia_perdida_declarada_bolsa_argentina'] = data_prepos['ganancia_perdida_declarada_bolsa_argentina'].apply(lambda x: np.tanh(x))\n",
    "    data_prepos = data_prepos.drop(['trabajo_No contesto'],axis = 1)\n",
    "    data_prepos = data_prepos.drop(['genero_mujer'],axis = 1)\n",
    "    data_prepos = data_prepos.drop(['estado_marital_divorciado'],axis = 1)\n",
    "\n",
    "    return data_prepos\n",
    "\n",
    "\n",
    "\n",
    "df = obtenerDFTraining()\n",
    "(X,y) = preprocesar_data_frame(df)\n",
    "X_prepos= prepros_dummies(X)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_prepos, y, test_size=0.25, random_state=RANDOM_STATE)\n",
    "#x_train, x_test, y_train, y_test  = preprocesar_df_pca(df[['ganancia_perdida_declarada_bolsa_argentina','trabajo',\n",
    "#                                      'estado_marital',\"anios_estudiados\",'genero',\"tiene_alto_valor_adquisitivo\"]],18)\n",
    "\n",
    "#x_train, x_test, y_train, y_test  = preprocesar_df_pca(df,30)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape=(24,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "opt = keras.optimizers.Adam()\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "h = model.fit(x_train, y_train, epochs=1000,batch_size=1000, verbose=0, validation_split=0.3)\n",
    "\n",
    "plt.figure(dpi=125, figsize=(12, 4))\n",
    "plt.plot(h.history['loss'], label=\"loss\")\n",
    "plt.plot(h.history['val_loss'], label=\"validation loss\")\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(dpi=125, figsize=(12, 6))\n",
    "plt.plot(h.history['accuracy'], label=\"accuracy\")\n",
    "plt.plot(h.history['val_accuracy'], label=\"validation accuracy\")\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ec021b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test,h.model.predict(x_test,verbose =4 )>0.5))\n",
    "print(classification_report(y_test,h.model.predict(x_test,verbose =4 )>0.45))\n",
    "print(classification_report(y_test,h.model.predict(x_test,verbose =4 )>0.40))\n",
    "\n",
    "h.model.predict(x_test,verbose =4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dc3f64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
